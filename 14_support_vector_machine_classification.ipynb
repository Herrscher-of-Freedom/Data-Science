{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification Task dengan Support Vector Machine (SVM)\n",
    "\n",
    "Referensi: [https://www.svm-tutorial.com/](https://www.svm-tutorial.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Konsep Dasar\n",
    "\n",
    "### Decision Boundary (Hyperplane)\n",
    "\n",
    "<!-- ![](./images/svm_linear.png) -->\n",
    "<div>\n",
    "<img src=\"./images/svm_linear.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terdapat 2 class yaitu hitam dan putih\n",
    "- Feature berjumlah 2 yakni X1 dan X2\n",
    "- Pemisah antar class sering dikenal sebagai decision boundary\n",
    "- Garis H1 tidak dapat dijadikan garis pemisah antar 2 class yang dimiliki\n",
    "- Garis H2 dan garis H3 memisahkan 2 class dengan sempurna\n",
    "- Dari garis H1, H2, dan H3, yang paling baik untuk merupakan decision boundary adalah H3 karena memiliki margin yang lebih besar bila dibandingkan dengan garis H2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperplane\n",
    "\n",
    "Terminologi yang akan dipelajari adalah Hyperplane. Merupakan termimologi yang umum digunakan untuk decision boundary.\n",
    "\n",
    "- Terdapat 2 feature yang diplotting menjadi 2 dimensi\n",
    "- Jika dalam sebuah kasus hanya memiliki 1 class saja, maka tidak ada garis pemisah melainkan hanya terdapat sebuah titik\n",
    "- Jika terdapat 3 feature, maka di decision boundary nya berupa sebuah bidang datar atau dikenal dengan claim\n",
    "- Jika terdapat 4 atau lebih dari 4 feature, maka pemisah antar classnya berupa bidang multi dimensi atau biasa dikenal dengan instilah hyperplane\n",
    "\n",
    "Dalam SVM, untuk proses penyederhanaan istilah maka setiap decision boundary umumnya akan disebut dengan hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Maximum Margin\n",
    "Penentuan Margin berdasarkan jarak terdekat antara decision boundary dengan anggota dari class yang ingin dipisahkan.\n",
    "\n",
    "<!-- ![](./images/svm_margin.png) -->\n",
    "<div>\n",
    "<img src=\"./images/svm_margin.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terdapat 2 class yaitu biru dan hijau\n",
    "- Feature berjumlah 2  yaitu X1 dan X2\n",
    "- Terdapat garis decision boundary berwarna merah yang digunakan untuk memisahkan class biru dan hijau\n",
    "- Area yang berwarna kuning disebut margin\n",
    "- Margin diperoleh berdasarkan jarak terdekat decision boundary dengan anggota class yang ingin dipisahkan\n",
    "- Anggota class yang ingin dipisahkan, dikenal sebagai support vector\n",
    "- Ada 3 support vector pada kasus ini, yaitu 2 bulat biru yang berada di garis putus-putus biru dan 1 bulat hijau yang terletak pada garis putus-putus hijau.\n",
    "\n",
    "SVM memilih berdasarkan margin terbesar (maximum margin) untuk menentukan decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linearly Inseperable <br/>& Kernel Tricks\n",
    "Referensi: [https://www.quora.com/What-is-the-kernel-trick](https://www.quora.com/What-is-the-kernel-trick)\n",
    "<div>\n",
    "<img src=\"./images/svm_kernel_01.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "<p/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting di foto kiri :\n",
    "- Terdapat 2 class, yaitu class titik dan class X\n",
    "- Terdapat 2 buah feature, sehingga ketika dilakukan plotting akan mendapatkan plotting 2 dimensi\n",
    "- Kondisi yang tidak memungkinkan untuk menarik garis linear dikenal drngan linearly inseperable\n",
    "- Untuk mengatasi masalah linearly inseperable, SVM akan mengkonversikan data yang ada ke dimensi yang lebih tinggi\n",
    "\n",
    "Plotting di foto kanan:\n",
    "- Merupakan hasil plotting 3 dimensi dari data sebelumnya yang berbentuk 2 dimensi\n",
    "- Kedua class dapat dipisahkan dengan mudah menggunakan bidang datar yang akan berperan sebagai decision boundary untuk memisahkan class X dengan class titik\n",
    "- Kernel Tricks adalah teknik SVM yang cocok untuk kasus ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset: The MNIST database of handwritten digits\n",
    "\n",
    "Referensi: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kasus ini mengadopsi Handwritten Digits Dataset (Open Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cara Mengakses Dataset :\n",
    "1. Import modul fetch_openml\n",
    "2. Panggil fetch_openml beserta parameternya.\n",
    "\n",
    "- Variabel x akan menampung sekumpulan nilai features\n",
    "- Variabel y akan menampung sekumpulan nilai target label\n",
    "- Dimensi dari variabel X 70000 untuk jumlah baris dan 784 untuk jumlah kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', data_home='./dataset/mnist', return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menampilkan 8 Data Pertama dari Dataset yang digunakan\n",
    "\n",
    "Dataset yang dimiliki berupa data gambar maka matplotlib akan digunakan untuk menampilkan datanya. \n",
    "1. import matplotlib.pyplot as plt\n",
    "2. import matplotlib.cm as cm (color map)\n",
    "3. Gunakan loop untuk menampilkan 8 data pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "pos = 1\n",
    "for data in X[:8]:\n",
    "    plt.subplot(1, 8, pos)\n",
    "    plt.imshow(data.reshape((28, 28)), \n",
    "               cmap=cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "    pos += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', '1', '9', '2', '1', '3'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:8] #8 Label yang berkorelasi dengan Gambar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dan Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X[:60000]\n",
    "#y_train = y[:60000]\n",
    "#X_test = X[60000:]\n",
    "#y_test = y[60000:]\n",
    "\n",
    "#Anda bisa melakukan training menggunakan command diatas berhubung komputer saya tidak mampu menghandle 60000 data maka saya gunakan training dibawah ini.\n",
    "\n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_test = X[69000:]\n",
    "y_test = y[69000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification dengan SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modul yang digunakan adalah Modul SVC\n",
    "- Import modul SVC\n",
    "- Bentuk objek modelnyan dengan parameter random_state=0 dan ditampung dalam variabel model\n",
    "- Lakukan model.fit untuk X_train dan y_trainnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavilion\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah Model di Training akan dilakukan evaluasi performa menggunakan classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       102\n",
      "           1       0.00      0.00      0.00       119\n",
      "           2       0.00      0.00      0.00        99\n",
      "           3       0.00      0.00      0.00       102\n",
      "           4       0.00      0.00      0.00        92\n",
      "           5       0.00      0.00      0.00        85\n",
      "           6       0.00      0.00      0.00       102\n",
      "           7       0.12      1.00      0.21       115\n",
      "           8       0.00      0.00      0.00        94\n",
      "           9       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.12      1000\n",
      "   macro avg       0.01      0.10      0.02      1000\n",
      "weighted avg       0.01      0.12      0.02      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavilion\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter Tuning dengan `GridSearchCV`\n",
    "Referensi: [https://en.wikipedia.org/wiki/Hyperparameter_optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)\n",
    "\n",
    "Parameter yang digunakan untuk mengatur parameter dari suatu Model dikenal dengan Hyperparameter. Proses untuk mencari suatu nilai optimum dari Hyperparameter dikenal Hyperparameter Tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses Menggunakannya : \n",
    "1. Import modul menggunakan from sklearn.model_selection import GridSearchCV\n",
    "2. Kemudian spesifikasikan sekumpulan parameter beserta pilihan nilai yang akan dikombinasikan\n",
    "3. Pada setiap parameter ditentukan pilihan nilainya\n",
    "4. Kemudian bentuk objek dari GrisSearchCV dengan menyertakan beberapa parameter yang diberi nilai\n",
    "5. Setelah objek GridSearchCV nya terbentuk maka akan ditampung ke dalam variabel grid_search, selanjutnya lakukan pemanggilan dengan menggunakan metode fit melalui objek grid_searh nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavilion\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:   22.2s finished\n",
      "C:\\Users\\Pavilion\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=0, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=6,\n",
       "             param_grid={'C': [0.5, 1, 10, 100],\n",
       "                         'gamma': ['scale', 1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'C': [0.5, 1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=SVC(random_state=0),\n",
    "                           param_grid=parameters,\n",
    "                           n_jobs=6,\n",
    "                           verbose=1,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat Best Score dan Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.899\n",
      "Best Parameters:\n",
      "\tkernel: rbf\n",
      "\tC: 10\n",
      "\tgamma: scale\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {grid_search.best_score_}')\n",
    "\n",
    "best_params = grid_search.best_estimator_.get_params()\n",
    "print(f'Best Parameters:')\n",
    "for param in parameters:\n",
    "    print(f'\\t{param}: {best_params[param]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       102\n",
      "           1       0.98      0.99      0.98       119\n",
      "           2       0.87      0.85      0.86        99\n",
      "           3       0.99      0.89      0.94       102\n",
      "           4       0.91      0.95      0.93        92\n",
      "           5       0.92      0.89      0.90        85\n",
      "           6       0.93      0.94      0.94       102\n",
      "           7       0.93      0.93      0.93       115\n",
      "           8       0.89      0.95      0.92        94\n",
      "           9       0.92      0.88      0.90        90\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.92      0.92      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
